{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77b775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32642e5c",
   "metadata": {},
   "source": [
    "The main Environment functions are -\n",
    "\n",
    "env.reset() -> Reset the environment and obtain initial observations\n",
    "env.render() -> Visualize the environment\n",
    "env.step() -> Apply an action to the environment\n",
    "env.close() -> Close down the render frame\n",
    "\n",
    "Evaluation metrics - \n",
    "\n",
    "ep_len_mean -> on average how long a particular episode lasted before done\n",
    "ep_rew_mean -> the average reward that the agent accumulated per episode\n",
    "\n",
    "CartPole Reward -\n",
    "\n",
    "Reward for CartPole is calculated as 1 point for every step that the pole remains upright. If the pole is more than 12 degrees from vertical or the cart moves more than 2.4 units from center, the episode ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b8ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"CartPole-v1\"\n",
    "env = gym.make(env_name, render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e44b7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khandelw2\\AppData\\Local\\anaconda3\\envs\\rl\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:28.0\n",
      "Episode:2 Score:20.0\n",
      "Episode:3 Score:54.0\n",
      "Episode:4 Score:10.0\n",
      "Episode:5 Score:10.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    terminated, truncated = False, False\n",
    "    score = 0\n",
    "    \n",
    "    while not (terminated or truncated):\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, terminated, truncated, info = env.step(action)\n",
    "        score += reward\n",
    "        \n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eeb6124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Logs'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path = os.path.join(\"Training\", \"Logs\")\n",
    "log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2568ced6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khandelw2\\AppData\\Local\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name, render_mode='human')\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7de64f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khandelw2\\AppData\\Local\\anaconda3\\envs\\rl\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 22.1     |\n",
      "|    ep_rew_mean     | 22.1     |\n",
      "| time/              |          |\n",
      "|    fps             | 42       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 26.5         |\n",
      "|    ep_rew_mean          | 26.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 44           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 92           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0090353405 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.686       |\n",
      "|    explained_variance   | -0.00323     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.08         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0158      |\n",
      "|    value_loss           | 50.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 33.4        |\n",
      "|    ep_rew_mean          | 33.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011359571 |\n",
      "|    clip_fraction        | 0.0743      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.67       |\n",
      "|    explained_variance   | 0.103       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.2        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.4        |\n",
      "|    ep_rew_mean          | 44.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 45          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 179         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008711131 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.636      |\n",
      "|    explained_variance   | 0.228       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    value_loss           | 53.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 56         |\n",
      "|    ep_rew_mean          | 56         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 45         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 223        |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00804319 |\n",
      "|    clip_fraction        | 0.07       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.609     |\n",
      "|    explained_variance   | 0.22       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.5       |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -0.018     |\n",
      "|    value_loss           | 67.3       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 73          |\n",
      "|    ep_rew_mean          | 73          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 266         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007490523 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.596      |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 56.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92.1         |\n",
      "|    ep_rew_mean          | 92.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 309          |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074002454 |\n",
      "|    clip_fraction        | 0.0846       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.582       |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20           |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.0145      |\n",
      "|    value_loss           | 48.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 108         |\n",
      "|    ep_rew_mean          | 108         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009189798 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.581      |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 39.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 127         |\n",
      "|    ep_rew_mean          | 127         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 46          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 394         |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006128736 |\n",
      "|    clip_fraction        | 0.0514      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.577      |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.2         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 146          |\n",
      "|    ep_rew_mean          | 146          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 437          |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019806065 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.549       |\n",
      "|    explained_variance   | 0.172        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.2         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    value_loss           | 62.6         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1e94677ce80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffdfa841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Saved Models\\\\PPO_model'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPO_path = os.path.join('Training', 'Saved Models', 'PPO_model')\n",
    "PPO_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c7232d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d4ffa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bba8d5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khandelw2\\AppData\\Local\\anaconda3\\envs\\rl\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(PPO_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e252720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e85e55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(325.0, 175.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=2, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd473711",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b2881",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"CartPole-v1\"\n",
    "env = gym.make(env_name, render_mode='human')\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    terminated, truncated = False, False\n",
    "    score = 0\n",
    "    \n",
    "    while not (terminated or truncated):\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, terminated, info = env.step(action)\n",
    "        score += reward\n",
    "        \n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "    \n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
